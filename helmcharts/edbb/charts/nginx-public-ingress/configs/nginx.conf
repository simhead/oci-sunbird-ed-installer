user  nginx;
worker_processes  auto;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;
events {
    worker_connections  10000;
}
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    {{- if .Values.global.local_development }}
    resolver 10.0.0.10;
    {{- else }}
    resolver {{ (lookup "v1" "Service" "kube-system" "kube-dns").spec.clusterIP }} valid=30s;
    {{- end }}
    lua_load_resty_core off;
    log_format  main  '$remote_addr - $remote_user [$time_local] '
                      '"$request" $status $request_length $body_bytes_sent'
                      ' $request_time $upstream_response_time $pipe'
                      ' "$http_referer" "$http_user_agent" "$sb_request_id"'
                      ' "$http_x_device_id" "$http_x_channel_id" "$http_x_app_id"'
                      ' "$http_x_app_ver" "$http_x_session_id" ';
    access_log  /var/log/nginx/access.log  main;
    # Shared dictionary to store metrics
    lua_shared_dict prometheus_metrics 100M;
    lua_package_path "/etc/nginx/lua_modules/?.lua";
    # Defining request_id
    # If the client send request_id it should be preffered over the default one
    map $http_x_request_id $sb_request_id {
      default  $http_x_request_id;
      ''  $request_id;
    }
    # Defining upstream cache status for nginx metrics
    map $upstream_cache_status $cache_status {
      default  $upstream_cache_status;
      ''       "NONE";
    }
    map $http_accept $dial_upstream_host {
      default                player;
      application/ld+json    kong;
    }
    # Defining metrics
    init_worker_by_lua_block {
      prometheus = require("prometheus").init("prometheus_metrics")
      metric_requests = prometheus:counter(
        "nginx_http_requests_total", "Number of HTTP requests", {"host", "status", "request_method", "cache_status"})
      metric_latency = prometheus:histogram(
        "nginx_http_request_duration_seconds", "HTTP request latency", {"host"})
      metric_connections = prometheus:gauge(
        "nginx_http_connections", "Number of HTTP connections", {"state"})
    }
    log_by_lua_block {
      metric_requests:inc(1, {ngx.var.server_name, ngx.var.status, ngx.var.request_method, ngx.var.cache_status })
      metric_latency:observe(tonumber(ngx.var.request_time), {ngx.var.server_name})
    }
    header_filter_by_lua_block {
     ngx.header["server"] = nil
    }
    sendfile        on;
    #tcp_nopush     on;
    client_max_body_size 60M;
    keepalive_timeout  65s;
    keepalive_requests 200;
    # Nginx connection limit per ip
    limit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;
    limit_conn_status 429;
    upstream kong {
        server kong:8000;
        keepalive 1000;
    }
    upstream keycloak {
        server keycloak:8080;
        keepalive 1000;
    }
    upstream player {
        server player:3000;
        keepalive 1000;
    }
    include /etc/nginx/defaults.d/*.conf;
    include /etc/nginx/conf.d/*.conf;
    #################
    # Caching Block #
    #################
    #
    # Keywords
    #
    # proxy_cache_path: path to store the cache content
    # level: how many directories we need, 1:2 means 1 parent directory, and another child directory before the cache content.
    # keys_zone: name of the cache and size of the keys store in RAM; 1â€‘MB zone can store data for about 8,000 keys
    # max_size: size of the cache content in disk
    # inactive: specifies how long an item can remain in the cache without being accessed. This doesn't value expiry time of cache. So keep it more than the expiry.
    # use_temp_path: do we have to write the cache to a temp path first? This will reduce the performance.
    #
    # caching for images and files
    proxy_cache_path /tmp/large_cache levels=1:2 keys_zone=large_cache:{{ .Values.large_cache_keys }} max_size=100m inactive=10m use_temp_path=off;
    proxy_cache_path /tmp/medium_cache levels=1:2 keys_zone=medium_cache:{{ .Values.medium_cache_keys }} max_size=50m inactive=10m use_temp_path=off;
    proxy_cache_path /tmp/small_cache levels=1:2 keys_zone=small_cache:{{ .Values.small_cache_keys }} max_size=10m inactive=10m use_temp_path=off;

   server {
     listen 9145;
     location /metrics {
       content_by_lua_block {
          metric_connections:set(ngx.var.connections_reading, {"reading"})
          metric_connections:set(ngx.var.connections_waiting, {"waiting"})
          metric_connections:set(ngx.var.connections_writing, {"writing"})
          prometheus:collect()
        }
     }
   }
}
